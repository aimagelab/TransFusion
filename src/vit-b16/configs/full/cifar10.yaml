# pytorch_lightning==2.0.2
trainer:
  accelerator: gpu
  devices: 1
  precision: 16-mixed
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: vit-b16-finetuning-cifar10 
  max_epochs: 300
  check_val_every_n_epoch: 2
model:
  model_name: vit-b16-224
  training_mode: full
  optimizer: adamw
  lr: 0.00005
  # momentum: 0.9
  weight_decay: 0.01
  dropout: 0.1
  scheduler: cosine
  warmup_steps: 5
  from_scratch: True

data:
  dataset: cifar10
  root: /work/debiasing/datasets
  size: 224
  batch_size: 128
  workers: 4
  mean: [0.4914, 0.4822, 0.4465]
  std: [0.2470, 0.2435, 0.2616]
model_checkpoint:
  dirpath : /work/debiasing/frinaldi/vit-b-finetuning/cifar10/
  filename: best-step-{step}-{val_acc:.4f}
  monitor: val_loss
  save_last: true
  mode: min
